{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Custom Spacy Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generic_token(type=\"word\", token=[], shape=[], capitalization=[], part_of_speech=[], length=[], prefix=\"\", suffix=\"\", is_followed_by_space=\"\", is_required=\"true\", is_in_output=\"true\", is_out_of_vocabulary=\"\", is_in_vocabulary=\"\", contain_digit=\"\"):\n",
    "    return {\n",
    "        \"type\": type,\n",
    "        \"token\": token,\n",
    "        \"shapes\": shape,\n",
    "        \"capitalization\": capitalization,\n",
    "        \"part_of_speech\": part_of_speech,\n",
    "        \"length\": length,\n",
    "        \"prefix\": prefix,\n",
    "        \"suffix\": suffix,\n",
    "        \"is_followed_by_space\": is_followed_by_space,\n",
    "        \"is_required\": is_required,\n",
    "        \"is_in_output\": is_in_output,\n",
    "        \"is_out_of_vocabulary\": is_out_of_vocabulary,\n",
    "        \"is_in_vocabulary\": is_in_vocabulary,\n",
    "        \"contain_digit\": contain_digit\n",
    "    }\n",
    "def word_token(token=[], capitalization=[], part_of_speech=[], length=[], prefix=\"\", suffix=\"\", is_followed_by_space=\"\", is_required=\"true\", is_in_output=\"false\", is_out_of_vocabulary=\"\", is_in_vocabulary=\"\", contain_digit=\"\"):\n",
    "     return generic_token(type=\"word\", token=token, capitalization=capitalization, part_of_speech=part_of_speech, length=length, prefix=prefix, suffix=suffix, is_followed_by_space=is_followed_by_space, is_required=is_required, is_in_output=is_in_output, is_out_of_vocabulary=is_out_of_vocabulary, is_in_vocabulary=is_in_vocabulary, contain_digit=contain_digit)\n",
    "    \n",
    "def punctuation_token(token=[], capitalization=[], part_of_speech=[], length=[], prefix=\"\", suffix=\"\", is_followed_by_space=\"\", is_required=\"true\", is_in_output=\"false\", is_out_of_vocabulary=\"\", is_in_vocabulary=\"\", contain_digit=\"\"):\n",
    "     return generic_token(type=\"punctuation\", token=token, capitalization=capitalization, part_of_speech=part_of_speech, length=length, prefix=prefix, suffix=suffix, is_followed_by_space=is_followed_by_space, is_required=is_required, is_in_output=is_in_output, is_out_of_vocabulary=is_out_of_vocabulary, is_in_vocabulary=is_in_vocabulary, contain_digit=contain_digit)\n",
    "\n",
    "def shape_token(shape=[], capitalization=[], part_of_speech=[], length=[], prefix=\"\", suffix=\"\", is_followed_by_space=\"\", is_required=\"true\", is_in_output=\"false\", is_out_of_vocabulary=\"\", is_in_vocabulary=\"\", contain_digit=\"\"):\n",
    "     return generic_token(type=\"shape\", shape=shape, capitalization=capitalization, part_of_speech=part_of_speech, length=length, prefix=prefix, suffix=suffix, is_followed_by_space=is_followed_by_space, is_required=is_required, is_in_output=is_in_output, is_out_of_vocabulary=is_out_of_vocabulary, is_in_vocabulary=is_in_vocabulary, contain_digit=contain_digit)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampe_rules = {\n",
    "  \"rules\": [\n",
    "      {\n",
    "      \"identifier\": \"an indentifier\",\n",
    "      \"description\": \"a description\",\n",
    "      \"is_active\": \"true/false\",\n",
    "      \"polarity\": [],\n",
    "      \"pattern\": [\n",
    "        {\n",
    "          \"type\": \"word\",\n",
    "          \"token\": [\"tOWN\", \"job\"],\n",
    "          \"capitalization\": [\"title\", \"upper\", \"mixed\", \"lower\", \"exact\"],\n",
    "          \"part_of_speech\": [\"noun\", \"pronoun\", \"NOT punctuation\"],\n",
    "          \"length\": [],\n",
    "          \"can_include_digits\": \"true/false\",\n",
    "          \"prefix\": \"ssss\",\n",
    "          \"suffix\": \"\",\n",
    "#           \"is_followed_by_space\": \"true/false\",\n",
    "          \"is_required\": \"false\",\n",
    "          \"is_in_output\": \"true/false\",\n",
    "          \"is_out_of_vocabulary\": \"true\",\n",
    "          \"is_in_vocabulary\":\"\",\n",
    "          \"contain_digit\":\"\"\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"word\",\n",
    "          \"token\": [],\n",
    "          \"capitalization\": [\"lower\", \"upper\", \"mixed\"],\n",
    "          \"part_of_speech\": [],\n",
    "          \"length\": [5, 7],\n",
    "          \"prefix\": \"SA\",\n",
    "          \"suffix\": \"WF\",\n",
    "          \"is_followed_by_space\": \"true/false\",\n",
    "          \"is_required\": \"true\",\n",
    "          \"is_in_output\": \"true/false\",\n",
    "          \"is_out_of_vocabulary\": \"true\",\n",
    "          \"is_in_vocabulary\":\"\",\n",
    "          \"contain_digit\":\"\"\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"word\",\n",
    "          \"token\": [],\n",
    "          \"capitalization\": [],\n",
    "          \"part_of_speech\": [],\n",
    "          \"length\": [],\n",
    "          \"prefix\": \"EEW\",\n",
    "          \"suffix\": \"RHI\",\n",
    "          \"is_followed_by_space\": \"true/false\",\n",
    "          \"is_required\": \"false\",\n",
    "          \"is_in_output\": \"true/false\",\n",
    "          \"is_out_of_vocabulary\": \"true\",\n",
    "          \"is_in_vocabulary\":\"\",\n",
    "          \"contain_digit\":\"\"\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"number\",\n",
    "          \"tokens\": [],\n",
    "          \"length\": [],\n",
    "          \"prefix\": [],\n",
    "          \"suffix\": [],\n",
    "          \"min\":\"\",\n",
    "          \"max\":\"\",\n",
    "          \"is_followed_by_space\": \"true/false\",\n",
    "          \"is_required\": \"true/false\",\n",
    "          \"is_in_output\": \"true/false\"\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"shape\",\n",
    "          \"shapes\": [\"xxxx\", \"xxxxxx\", \"XXXXXdd.dddXXxxxxxxx\"],\n",
    "          \"part_of_speech\": [],\n",
    "          \"prefix\": \"ss\",\n",
    "          \"suffix\": \"pp\",\n",
    "          \"is_followed_by_space\": \"true/false\",\n",
    "          \"is_required\": \"true\",\n",
    "          \"is_in_output\": \"true\"\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"punctuation\",\n",
    "          \"token\": [\",\", \"?\"],\n",
    "          \"is_followed_by_space\": \"true/false\",\n",
    "          \"is_required\": \"false\",\n",
    "          \"is_in_output\": \"true\"\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"symbol\",\n",
    "          \"token\": [],\n",
    "          \"is_followed_by_space\": \"true/false\",\n",
    "          \"is_required\": \"true/false\",\n",
    "          \"is_in_output\": \"true/false\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from etk.core import Core\n",
    "c = Core()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': u\"Hello guy's, it's Jessica here from the #@%%% Spa. I cant say the name on here, and it is JessicaLa, and it is Cold\\nHi Gentlemen, My name is Ashley . my name Monica I am the one and, My names is Alanda\\nName : Sara . I am the one and, Name: JILL , Name:Jessie\\nAshley (702)628-9035 XOXO . Aslll (702) 628-9035 XOXO Alppp 7026289035\\nI'm Ashley I'm bored i am All, I am ALL\\nthis is Ashleyb I'm bored This is Ashleya  This is AshleyC\", 'simple_tokens_original_case': [u'Hello', u'guy', u\"'\", u's', u',', u'it', u\"'\", u's', u'Jessica', u'here', u'from', u'the', u'#', u'@', u'%', u'%', u'%', u'Spa', u'.', u'I', u'cant', u'say', u'the', u'name', u'on', u'here', u',', u'and', u'it', u'is', u'JessicaLa', u',', u'and', u'it', u'is', u'Cold', u'\\n', u'Hi', u'Gentlemen', u',', u'My', u'name', u'is', u'Ashley', u'.', u'my', u'name', u'Monica', u'I', u'am', u'the', u'one', u'and', u',', u'My', u'names', u'is', u'Alanda', u'\\n', u'Name', u':', u'Sara', u'.', u'I', u'am', u'the', u'one', u'and', u',', u'Name', u':', u'JILL', u',', u'Name', u':', u'Jessie', u'\\n', u'Ashley', u'(', u'702', u')', u'628', u'-', u'9035', u'XOXO', u'.', u'Aslll', u'(', u'702', u')', u'628', u'-', u'9035', u'XOXO', u'Alppp', u'7026289035', u'\\n', u'I', u\"'\", u'm', u'Ashley', u'I', u\"'\", u'm', u'bored', u'i', u'am', u'All', u',', u'I', u'am', u'ALL', u'\\n', u'this', u'is', u'Ashleyb', u'I', u\"'\", u'm', u'bored', u'This', u'is', u'Ashleya', u'This', u'is', u'AshleyC']}\n"
     ]
    }
   ],
   "source": [
    "# Text to test the rules\n",
    "t = []\n",
    "t.append(u\"Hello guy's, it's Jessica here from the #@%%% Spa. I cant say the name on here, and it is JessicaLa, and it is Cold\")\n",
    "t.append(u\"Hi Gentlemen, My name is Ashley . my name Monica I am the one and, My names is Alanda\")\n",
    "t.append(u\"Name : Sara . I am the one and, Name: JILL , Name:Jessie\")\n",
    "t.append(u\"Ashley (702)628-9035 XOXO . Aslll (702) 628-9035 XOXO Alppp 7026289035\")\n",
    "t.append(u\"I'm Ashley I'm bored i am All, I am ALL\")\n",
    "t.append(u\"this is Ashleyb I'm bored This is Ashleya  This is AshleyC\")\n",
    "\n",
    "d = dict()\n",
    "d['text'] = \"\\n\".join(t)\n",
    "d['simple_tokens_original_case'] = c.extract_tokens_from_crf(c.extract_crftokens(d['text'], lowercase=False))\n",
    "\n",
    "print d\n",
    "\n",
    "config = dict()\n",
    "config['field_name'] = 'field02'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: Hello guy's, it's Jessica here from the #@%%% Spa. I cant say the name on here, and it is JessicaLa, and it is Cold\n",
      "Hi Gentlemen, My name is Ashley . my name Monica I am the one and, My names is Alanda\n",
      "Name : Sara . I am the one and, Name: JILL , Name:Jessie\n",
      "Ashley (702)628-9035 XOXO . Aslll (702) 628-9035 XOXO Alppp 7026289035\n",
      "I'm Ashley I'm bored i am All, I am ALL\n",
      "this is Ashleyb I'm bored This is Ashleya  This is AshleyC\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# my name / names is\n",
    "\n",
    "rule_01 = {\n",
    "      \"identifier\": \"name_rule_01\",\n",
    "      \"description\": \"a description\",\n",
    "      \"is_active\": \"false\",\n",
    "      \"polarity\": [],\n",
    "      \"pattern\": [\n",
    "          word_token(token=[\"my\"]),\n",
    "          word_token(token=[\"name\", \"names\"]),\n",
    "          word_token(token=[\"is\"], is_required=\"false\"),\n",
    "          word_token(capitalization=[\"title\", \"upper\"], is_in_output=\"true\")\n",
    "      ]\n",
    "    }\n",
    "\n",
    "\n",
    "field_rules = {\n",
    "  \"rules\": [\n",
    "      rule_01\n",
    "  ]\n",
    "}\n",
    "\n",
    "print \"text:\", d['text']\n",
    "results = c.extract_using_custom_spacy(d, config, field_rules=field_rules)\n",
    "print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: Hello guy's, it's Jessica here from the #@%%% Spa. I cant say the name on here, and it is JessicaLa, and it is Cold\n",
      "Hi Gentlemen, My name is Ashley . my name Monica I am the one and, My names is Alanda\n",
      "Name : Sara . I am the one and, Name: JILL , Name:Jessie\n",
      "Ashley (702)628-9035 XOXO . Aslll (702) 628-9035 XOXO Alppp 7026289035\n",
      "I'm Ashley I'm bored i am All, I am ALL\n",
      "this is Ashleyb I'm bored This is Ashleya  This is AshleyC\n",
      "[{'context': {'start': 105, 'identifier': 'name_rule_02', 'end': 108, 'rule_id': 0}, 'value': 'All'}, {'context': {'start': 109, 'identifier': 'name_rule_02', 'end': 112, 'rule_id': 0}, 'value': 'ALL'}]\n"
     ]
    }
   ],
   "source": [
    "#i am \n",
    "\n",
    "rule_02 = {\n",
    "      \"identifier\": \"name_rule_02\",\n",
    "      \"description\": \"a description\",\n",
    "      \"is_active\": \"true\",\n",
    "      \"polarity\": [],\n",
    "      \"pattern\": [\n",
    "            word_token(token=[\"i\"]),\n",
    "            word_token(token=[\"am\"]),\n",
    "            word_token(capitalization=[\"title\", \"upper\"], is_in_output=\"true\")\n",
    "      ]\n",
    "    }\n",
    "\n",
    "field_rules = {\n",
    "  \"rules\": [\n",
    "      rule_02\n",
    "  ]\n",
    "}\n",
    "\n",
    "print \"text:\", d['text']\n",
    "results = c.extract_using_custom_spacy(d, config, field_rules=field_rules)\n",
    "print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: Hello guy's, it's Jessica here from the #@%%% Spa. I cant say the name on here, and it is JessicaLa, and it is Cold\n",
      "Hi Gentlemen, My name is Ashley . my name Monica I am the one and, My names is Alanda\n",
      "Name : Sara . I am the one and, Name: JILL , Name:Jessie\n",
      "Ashley (702)628-9035 XOXO . Aslll (702) 628-9035 XOXO Alppp 7026289035\n",
      "I'm Ashley I'm bored i am All, I am ALL\n",
      "this is Ashleyb I'm bored This is Ashleya  This is AshleyC\n",
      "[{'context': {'start': 59, 'identifier': 'name_rule_03', 'end': 62, 'rule_id': 0}, 'value': 'Sara'}, {'context': {'start': 69, 'identifier': 'name_rule_03', 'end': 72, 'rule_id': 0}, 'value': 'JILL'}, {'context': {'start': 73, 'identifier': 'name_rule_03', 'end': 76, 'rule_id': 0}, 'value': 'Jessie'}]\n"
     ]
    }
   ],
   "source": [
    "# name :  Name\n",
    "\n",
    "rule_03 = {\n",
    "      \"identifier\": \"name_rule_03\",\n",
    "      \"description\": \"a description\",\n",
    "      \"is_active\": \"true\",\n",
    "      \"polarity\": [],\n",
    "      \"pattern\": [\n",
    "          word_token(token=[\"name\"]),\n",
    "          punctuation_token(token=[\":\"]),\n",
    "          word_token(token=[], is_in_output=\"true\"),\n",
    "      ]\n",
    "    }\n",
    "\n",
    "field_rules = {\n",
    "  \"rules\": [\n",
    "      rule_03\n",
    "  ]\n",
    "}\n",
    "\n",
    "print \"text:\", d['text']\n",
    "results = c.extract_using_custom_spacy(d, config, field_rules=field_rules)\n",
    "print results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: Hello guy's, it's Jessica here from the #@%%% Spa. I cant say the name on here, and it is JessicaLa, and it is Cold\n",
      "Hi Gentlemen, My name is Ashley . my name Monica I am the one and, My names is Alanda\n",
      "Name : Sara . I am the one and, Name: JILL , Name:Jessie\n",
      "Ashley (702)628-9035 XOXO . Aslll (702) 628-9035 XOXO Alppp 7026289035\n",
      "I'm Ashley I'm bored i am All, I am ALL\n",
      "this is Ashleyb I'm bored This is Ashleya  This is AshleyC\n",
      "[{'context': {'start': 28, 'identifier': 'name_rule_04', 'end': 31, 'rule_id': 0}, 'value': 'JessicaLa'}, {'context': {'start': 33, 'identifier': 'name_rule_04', 'end': 36, 'rule_id': 0}, 'value': 'Cold'}]\n"
     ]
    }
   ],
   "source": [
    "# it is \n",
    "\n",
    "rule_04 = {\n",
    "      \"identifier\": \"name_rule_04\",\n",
    "      \"description\": \"a description\",\n",
    "      \"is_active\": \"true\",\n",
    "      \"polarity\": [],\n",
    "      \"pattern\": [\n",
    "          word_token(token=[\"it\"]),\n",
    "          word_token(token=[\"is\"]),\n",
    "#           word_token(capitalization=[\"title\", \"mixed\"], is_in_output=\"true\")\n",
    "          word_token(part_of_speech=[\"proper noun\"], is_in_output=\"true\")\n",
    "      ]\n",
    "    }\n",
    "\n",
    "field_rules = {\n",
    "  \"rules\": [\n",
    "      rule_04\n",
    "  ]\n",
    "}\n",
    "\n",
    "print \"text:\", d['text']\n",
    "results = c.extract_using_custom_spacy(d, config, field_rules=field_rules)\n",
    "print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: Hello guy's, it's Jessica here from the #@%%% Spa. I cant say the name on here, and it is JessicaLa, and it is Cold\n",
      "Hi Gentlemen, My name is Ashley . my name Monica I am the one and, My names is Alanda\n",
      "Name : Sara . I am the one and, Name: JILL , Name:Jessie\n",
      "Ashley (702)628-9035 XOXO . Aslll (702) 628-9035 XOXO Alppp 7026289035\n",
      "I'm Ashley I'm bored i am All, I am ALL\n",
      "this is Ashleyb I'm bored This is Ashleya  This is AshleyC\n",
      "[{'context': {'start': 113, 'identifier': 'name_rule_05', 'end': 116, 'rule_id': 0}, 'value': 'Ashleyb'}, {'context': {'start': 120, 'identifier': 'name_rule_05', 'end': 123, 'rule_id': 0}, 'value': 'Ashleya'}, {'context': {'start': 123, 'identifier': 'name_rule_05', 'end': 126, 'rule_id': 0}, 'value': 'AshleyC'}]\n"
     ]
    }
   ],
   "source": [
    "# this is , This is\n",
    "\n",
    "rule_05 = {\n",
    "      \"identifier\": \"name_rule_05\",\n",
    "      \"description\": \"a description\",\n",
    "      \"is_active\": \"true\",\n",
    "      \"polarity\": [],\n",
    "      \"pattern\": [\n",
    "          word_token(token=[\"this\"]),\n",
    "          word_token(token=[\"is\"]),\n",
    "          word_token(part_of_speech=[\"proper noun\"], capitalization=[\"title\", \"mixed\", \"upper\"], is_in_output=\"true\")\n",
    "      ]\n",
    "    }\n",
    "\n",
    "field_rules = {\n",
    "  \"rules\": [\n",
    "      rule_05\n",
    "  ]\n",
    "}\n",
    "\n",
    "\n",
    "print \"text:\", d['text']\n",
    "results = c.extract_using_custom_spacy(d, config, field_rules=field_rules)\n",
    "print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: Hello guy's, it's Jessica here from the #@%%% Spa. I cant say the name on here, and it is JessicaLa, and it is Cold\n",
      "Hi Gentlemen, My name is Ashley . my name Monica I am the one and, My names is Alanda\n",
      "Name : Sara . I am the one and, Name: JILL , Name:Jessie\n",
      "Ashley (702)628-9035 XOXO . Aslll (702) 628-9035 XOXO Alppp 7026289035\n",
      "I'm Ashley I'm bored i am All, I am ALL\n",
      "this is Ashleyb I'm bored This is Ashleya  This is AshleyC\n",
      "tokens: [u'Hello', u'guy', u\"'\", u's', u',', u'it', u\"'\", u's', u'Jessica', u'here', u'from', u'the', u'#', u'@', u'%', u'%', u'%', u'Spa', u'.', u'I', u'cant', u'say', u'the', u'name', u'on', u'here', u',', u'and', u'it', u'is', u'JessicaLa', u',', u'and', u'it', u'is', u'Cold', u'\\n', u'Hi', u'Gentlemen', u',', u'My', u'name', u'is', u'Ashley', u'.', u'my', u'name', u'Monica', u'I', u'am', u'the', u'one', u'and', u',', u'My', u'names', u'is', u'Alanda', u'\\n', u'Name', u':', u'Sara', u'.', u'I', u'am', u'the', u'one', u'and', u',', u'Name', u':', u'JILL', u',', u'Name', u':', u'Jessie', u'\\n', u'Ashley', u'(', u'702', u')', u'628', u'-', u'9035', u'XOXO', u'.', u'Aslll', u'(', u'702', u')', u'628', u'-', u'9035', u'XOXO', u'Alppp', u'7026289035', u'\\n', u'I', u\"'\", u'm', u'Ashley', u'I', u\"'\", u'm', u'bored', u'i', u'am', u'All', u',', u'I', u'am', u'ALL', u'\\n', u'this', u'is', u'Ashleyb', u'I', u\"'\", u'm', u'bored', u'This', u'is', u'Ashleya', u'This', u'is', u'AshleyC']\n",
      "[{'context': {'start': 97, 'identifier': 'name_rule_06', 'end': 101, 'rule_id': 0}, 'value': 'Ashley'}]\n"
     ]
    }
   ],
   "source": [
    "#I'm\n",
    "\n",
    "rule_06 = {\n",
    "      \"identifier\": \"name_rule_06\",\n",
    "      \"description\": \"a description\",\n",
    "      \"is_active\": \"true\",\n",
    "      \"polarity\": [],\n",
    "      \"pattern\": [\n",
    "          word_token(token=[\"i\"]),\n",
    "          punctuation_token(token=[\"'\"]),\n",
    "          word_token(token=[\"m\"]),\n",
    "          word_token(part_of_speech=[\"proper noun\"], capitalization=[\"title\", \"mixed\", \"upper\"], is_in_output=\"true\")\n",
    "      ]\n",
    "    }\n",
    "\n",
    "field_rules = {\n",
    "  \"rules\": [\n",
    "      rule_06\n",
    "  ]\n",
    "}\n",
    "\n",
    "print \"text:\", d['text']\n",
    "print \"tokens:\", d['simple_tokens_original_case']\n",
    "results = c.extract_using_custom_spacy(d, config, field_rules=field_rules)\n",
    "print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: Hello guy's, it's Jessica here from the #@%%% Spa. I cant say the name on here, and it is JessicaLa, and it is Cold\n",
      "Hi Gentlemen, My name is Ashley . my name Monica I am the one and, My names is Alanda\n",
      "Name : Sara . I am the one and, Name: JILL , Name:Jessie\n",
      "Ashley (702)628-9035 XOXO . Aslll (702) 628-9035 XOXO Alppp 7026289035\n",
      "I'm Ashley I'm bored i am All, I am ALL\n",
      "this is Ashleyb I'm bored This is Ashleya  This is AshleyC\n",
      "tokens: [u'Hello', u'guy', u\"'\", u's', u',', u'it', u\"'\", u's', u'Jessica', u'here', u'from', u'the', u'#', u'@', u'%', u'%', u'%', u'Spa', u'.', u'I', u'cant', u'say', u'the', u'name', u'on', u'here', u',', u'and', u'it', u'is', u'JessicaLa', u',', u'and', u'it', u'is', u'Cold', u'\\n', u'Hi', u'Gentlemen', u',', u'My', u'name', u'is', u'Ashley', u'.', u'my', u'name', u'Monica', u'I', u'am', u'the', u'one', u'and', u',', u'My', u'names', u'is', u'Alanda', u'\\n', u'Name', u':', u'Sara', u'.', u'I', u'am', u'the', u'one', u'and', u',', u'Name', u':', u'JILL', u',', u'Name', u':', u'Jessie', u'\\n', u'Ashley', u'(', u'702', u')', u'628', u'-', u'9035', u'XOXO', u'.', u'Aslll', u'(', u'702', u')', u'628', u'-', u'9035', u'XOXO', u'Alppp', u'7026289035', u'\\n', u'I', u\"'\", u'm', u'Ashley', u'I', u\"'\", u'm', u'bored', u'i', u'am', u'All', u',', u'I', u'am', u'ALL', u'\\n', u'this', u'is', u'Ashleyb', u'I', u\"'\", u'm', u'bored', u'This', u'is', u'Ashleya', u'This', u'is', u'AshleyC']\n",
      "[\n",
      "  {\n",
      "    \"context\": {\n",
      "      \"start\": 5, \n",
      "      \"identifier\": \"name_rule_07\", \n",
      "      \"end\": 9, \n",
      "      \"rule_id\": 0\n",
      "    }, \n",
      "    \"value\": \"Jessica\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#it's\n",
    "\n",
    "rule_07 = {\n",
    "      \"identifier\": \"name_rule_07\",\n",
    "      \"description\": \"a description\",\n",
    "      \"is_active\": \"true\",\n",
    "      \"polarity\": [],\n",
    "      \"pattern\": [\n",
    "          word_token(token=[\"it\"]),\n",
    "          punctuation_token(token=[\"'\"]),\n",
    "          word_token(token=[\"s\"]),\n",
    "          word_token(part_of_speech=[\"proper noun\"], capitalization=[\"title\", \"mixed\", \"upper\"], is_in_output=\"true\")          \n",
    "      ]\n",
    "    }\n",
    "\n",
    "field_rules = {\n",
    "  \"rules\": [\n",
    "      rule_07\n",
    "  ]\n",
    "}\n",
    "\n",
    "\n",
    "print \"text:\", d['text']\n",
    "print \"tokens:\", d['simple_tokens_original_case']\n",
    "results = c.extract_using_custom_spacy(d, config, field_rules=field_rules)\n",
    "print json.dumps(results, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: Hello guy's, it's Jessica here from the #@%%% Spa. I cant say the name on here, and it is JessicaLa, and it is Cold\n",
      "Hi Gentlemen, My name is Ashley . my name Monica I am the one and, My names is Alanda\n",
      "Name : Sara . I am the one and, Name: JILL , Name:Jessie\n",
      "Ashley (702)628-9035 XOXO . Aslll (702) 628-9035 XOXO Alppp 7026289035\n",
      "I'm Ashley I'm bored i am All, I am ALL\n",
      "this is Ashleyb I'm bored This is Ashleya  This is AshleyC\n",
      "tokens: [u'Hello', u'guy', u\"'\", u's', u',', u'it', u\"'\", u's', u'Jessica', u'here', u'from', u'the', u'#', u'@', u'%', u'%', u'%', u'Spa', u'.', u'I', u'cant', u'say', u'the', u'name', u'on', u'here', u',', u'and', u'it', u'is', u'JessicaLa', u',', u'and', u'it', u'is', u'Cold', u'\\n', u'Hi', u'Gentlemen', u',', u'My', u'name', u'is', u'Ashley', u'.', u'my', u'name', u'Monica', u'I', u'am', u'the', u'one', u'and', u',', u'My', u'names', u'is', u'Alanda', u'\\n', u'Name', u':', u'Sara', u'.', u'I', u'am', u'the', u'one', u'and', u',', u'Name', u':', u'JILL', u',', u'Name', u':', u'Jessie', u'\\n', u'Ashley', u'(', u'702', u')', u'628', u'-', u'9035', u'XOXO', u'.', u'Aslll', u'(', u'702', u')', u'628', u'-', u'9035', u'XOXO', u'Alppp', u'7026289035', u'\\n', u'I', u\"'\", u'm', u'Ashley', u'I', u\"'\", u'm', u'bored', u'i', u'am', u'All', u',', u'I', u'am', u'ALL', u'\\n', u'this', u'is', u'Ashleyb', u'I', u\"'\", u'm', u'bored', u'This', u'is', u'Ashleya', u'This', u'is', u'AshleyC']\n",
      "[{'context': {'start': 77, 'identifier': 'name_rule_08', 'end': 80, 'rule_id': 0}, 'value': 'Ashley'}, {'context': {'start': 86, 'identifier': 'name_rule_08', 'end': 89, 'rule_id': 0}, 'value': 'Aslll'}]\n"
     ]
    }
   ],
   "source": [
    "#Ashley (702)\n",
    "rule_08 = {\n",
    "      \"identifier\": \"name_rule_08\",\n",
    "      \"description\": \"a description\",\n",
    "      \"is_active\": \"true\",\n",
    "      \"polarity\": [],\n",
    "      \"pattern\": [\n",
    "          word_token(capitalization=[\"title\"], is_in_output=\"true\"),\n",
    "          punctuation_token(token=[\"(\", \"[\"]),\n",
    "          shape_token(shape=[\"ddd\"])\n",
    "      ]\n",
    "    }\n",
    "\n",
    "field_rules = {\n",
    "  \"rules\": [\n",
    "      rule_08\n",
    "  ]\n",
    "}\n",
    "\n",
    "print \"text:\", d['text']\n",
    "print \"tokens:\", d['simple_tokens_original_case']\n",
    "results = c.extract_using_custom_spacy(d, config, field_rules=field_rules)\n",
    "print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'context': {'start': 94, 'identifier': 'name_rule_09', 'end': 96, 'rule_id': 0}, 'value': 'Alppp'}]\n"
     ]
    }
   ],
   "source": [
    "#Jessica 7135975313\n",
    "\n",
    "rule_09 = {\n",
    "      \"identifier\": \"name_rule_09\",\n",
    "      \"description\": \"a description\",\n",
    "      \"is_active\": \"true\",\n",
    "      \"polarity\": [],\n",
    "      \"pattern\": [\n",
    "          word_token(capitalization=[\"title\", \"upper\", \"mixed\"], is_in_output=\"true\"),\n",
    "          shape_token(shape=[\"dddddddddd\"])\n",
    "      ]\n",
    "    }\n",
    "\n",
    "field_rules = {\n",
    "  \"rules\": [\n",
    "      rule_09\n",
    "  ]\n",
    "}\n",
    "\n",
    "results = c.extract_using_custom_spacy(d, config, field_rules=field_rules)\n",
    "print results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Several Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'context': {'start': 105, 'identifier': 'name_rule_02', 'end': 108, 'rule_id': 1}, 'value': 'All'}, {'context': {'start': 109, 'identifier': 'name_rule_02', 'end': 112, 'rule_id': 1}, 'value': 'ALL'}, {'context': {'start': 59, 'identifier': 'name_rule_03', 'end': 62, 'rule_id': 2}, 'value': 'Sara'}, {'context': {'start': 69, 'identifier': 'name_rule_03', 'end': 72, 'rule_id': 2}, 'value': 'JILL'}, {'context': {'start': 73, 'identifier': 'name_rule_03', 'end': 76, 'rule_id': 2}, 'value': 'Jessie'}, {'context': {'start': 28, 'identifier': 'name_rule_04', 'end': 31, 'rule_id': 3}, 'value': 'JessicaLa'}, {'context': {'start': 33, 'identifier': 'name_rule_04', 'end': 36, 'rule_id': 3}, 'value': 'Cold'}, {'context': {'start': 113, 'identifier': 'name_rule_05', 'end': 116, 'rule_id': 4}, 'value': 'Ashleyb'}, {'context': {'start': 120, 'identifier': 'name_rule_05', 'end': 123, 'rule_id': 4}, 'value': 'Ashleya'}, {'context': {'start': 123, 'identifier': 'name_rule_05', 'end': 126, 'rule_id': 4}, 'value': 'AshleyC'}, {'context': {'start': 97, 'identifier': 'name_rule_06', 'end': 101, 'rule_id': 5}, 'value': 'Ashley'}, {'context': {'start': 5, 'identifier': 'name_rule_07', 'end': 9, 'rule_id': 6}, 'value': 'Jessica'}, {'context': {'start': 77, 'identifier': 'name_rule_08', 'end': 80, 'rule_id': 7}, 'value': 'Ashley'}, {'context': {'start': 86, 'identifier': 'name_rule_08', 'end': 89, 'rule_id': 7}, 'value': 'Aslll'}, {'context': {'start': 94, 'identifier': 'name_rule_09', 'end': 96, 'rule_id': 8}, 'value': 'Alppp'}]\n",
      "{\"rules\": [{\"polarity\": [], \"pattern\": [{\"suffix\": \"\", \"capitalization\": [], \"part_of_speech\": [], \"prefix\": \"\", \"contain_digit\": \"\", \"is_in_vocabulary\": \"\", \"is_out_of_vocabulary\": \"\", \"is_in_output\": \"false\", \"length\": [], \"shapes\": [], \"token\": [\"my\"], \"is_followed_by_space\": \"\", \"is_required\": \"true\", \"type\": \"word\"}, {\"suffix\": \"\", \"capitalization\": [], \"part_of_speech\": [], \"prefix\": \"\", \"contain_digit\": \"\", \"is_in_vocabulary\": \"\", \"is_out_of_vocabulary\": \"\", \"is_in_output\": \"false\", \"length\": [], \"shapes\": [], \"token\": [\"name\", \"names\"], \"is_followed_by_space\": \"\", \"is_required\": \"true\", \"type\": \"word\"}, {\"suffix\": \"\", \"capitalization\": [], \"part_of_speech\": [], \"prefix\": \"\", \"contain_digit\": \"\", \"is_in_vocabulary\": \"\", \"is_out_of_vocabulary\": \"\", \"is_in_output\": \"false\", \"length\": [], \"shapes\": [], \"token\": [\"is\"], \"is_followed_by_space\": \"\", \"is_required\": \"false\", \"type\": \"word\"}, {\"suffix\": \"\", \"capitalization\": [\"title\", \"upper\"], \"part_of_speech\": [], \"prefix\": \"\", \"contain_digit\": \"\", \"is_in_vocabulary\": \"\", \"is_out_of_vocabulary\": \"\", \"is_in_output\": \"true\", \"length\": [], \"shapes\": [], \"token\": [], \"is_followed_by_space\": \"\", \"is_required\": \"true\", \"type\": \"word\"}], \"identifier\": \"name_rule_01\", \"is_active\": \"false\", \"description\": \"a description\"}, {\"polarity\": [], \"pattern\": [{\"suffix\": \"\", \"capitalization\": [], \"part_of_speech\": [], \"prefix\": \"\", \"contain_digit\": \"\", \"is_in_vocabulary\": \"\", \"is_out_of_vocabulary\": \"\", \"is_in_output\": \"false\", \"length\": [], \"shapes\": [], \"token\": [\"i\"], \"is_followed_by_space\": \"\", \"is_required\": \"true\", \"type\": \"word\"}, {\"suffix\": \"\", \"capitalization\": [], \"part_of_speech\": [], \"prefix\": \"\", \"contain_digit\": \"\", \"is_in_vocabulary\": \"\", \"is_out_of_vocabulary\": \"\", \"is_in_output\": \"false\", \"length\": [], \"shapes\": [], \"token\": [\"am\"], \"is_followed_by_space\": \"\", \"is_required\": \"true\", \"type\": \"word\"}, {\"suffix\": \"\", \"capitalization\": [\"title\", \"upper\"], \"part_of_speech\": [], \"prefix\": \"\", \"contain_digit\": \"\", \"is_in_vocabulary\": \"\", \"is_out_of_vocabulary\": \"\", \"is_in_output\": \"true\", \"length\": [], \"shapes\": [], \"token\": [], \"is_followed_by_space\": \"\", \"is_required\": \"true\", \"type\": \"word\"}], \"identifier\": \"name_rule_02\", \"is_active\": \"true\", \"description\": \"a description\"}, {\"polarity\": [], \"pattern\": [{\"suffix\": \"\", \"capitalization\": [], \"part_of_speech\": [], \"prefix\": \"\", \"contain_digit\": \"\", \"is_in_vocabulary\": \"\", \"is_out_of_vocabulary\": \"\", \"is_in_output\": \"false\", \"length\": [], \"shapes\": [], \"token\": [\"name\"], \"is_followed_by_space\": \"\", \"is_required\": \"true\", \"type\": \"word\"}, {\"suffix\": \"\", \"capitalization\": [], \"part_of_speech\": [], \"prefix\": \"\", \"contain_digit\": \"\", \"is_in_vocabulary\": \"\", \"is_out_of_vocabulary\": \"\", \"is_in_output\": \"false\", \"length\": [], \"shapes\": [], \"token\": [\":\"], \"is_followed_by_space\": \"\", \"is_required\": \"true\", \"type\": \"punctuation\"}, {\"suffix\": \"\", \"capitalization\": [], \"part_of_speech\": [], \"prefix\": \"\", \"contain_digit\": \"\", \"is_in_vocabulary\": \"\", \"is_out_of_vocabulary\": \"\", \"is_in_output\": \"true\", \"length\": [], \"shapes\": [], \"token\": [], \"is_followed_by_space\": \"\", \"is_required\": \"true\", \"type\": \"word\"}], \"identifier\": \"name_rule_03\", \"is_active\": \"true\", \"description\": \"a description\"}, {\"polarity\": [], \"pattern\": [{\"suffix\": \"\", \"capitalization\": [], \"part_of_speech\": [], \"prefix\": \"\", \"contain_digit\": \"\", \"is_in_vocabulary\": \"\", \"is_out_of_vocabulary\": \"\", \"is_in_output\": \"false\", \"length\": [], \"shapes\": [], \"token\": [\"it\"], \"is_followed_by_space\": \"\", \"is_required\": \"true\", \"type\": \"word\"}, {\"suffix\": \"\", \"capitalization\": [], \"part_of_speech\": [], \"prefix\": \"\", \"contain_digit\": \"\", \"is_in_vocabulary\": \"\", \"is_out_of_vocabulary\": \"\", \"is_in_output\": \"false\", \"length\": [], \"shapes\": [], \"token\": [\"is\"], \"is_followed_by_space\": \"\", \"is_required\": \"true\", \"type\": \"word\"}, {\"suffix\": \"\", \"capitalization\": [], \"part_of_speech\": [\"proper noun\"], \"prefix\": \"\", \"contain_digit\": \"\", \"is_in_vocabulary\": \"\", \"is_out_of_vocabulary\": \"\", \"is_in_output\": \"true\", \"length\": [], \"shapes\": [], \"token\": [], \"is_followed_by_space\": \"\", \"is_required\": \"true\", \"type\": \"word\"}], \"identifier\": \"name_rule_04\", \"is_active\": \"true\", \"description\": \"a description\"}, {\"polarity\": [], \"pattern\": [{\"suffix\": \"\", \"capitalization\": [], \"part_of_speech\": [], \"prefix\": \"\", \"contain_digit\": \"\", \"is_in_vocabulary\": \"\", \"is_out_of_vocabulary\": \"\", \"is_in_output\": \"false\", \"length\": [], \"shapes\": [], \"token\": [\"this\"], \"is_followed_by_space\": \"\", \"is_required\": \"true\", \"type\": \"word\"}, {\"suffix\": \"\", \"capitalization\": [], \"part_of_speech\": [], \"prefix\": \"\", \"contain_digit\": \"\", \"is_in_vocabulary\": \"\", \"is_out_of_vocabulary\": \"\", \"is_in_output\": \"false\", \"length\": [], \"shapes\": [], \"token\": [\"is\"], \"is_followed_by_space\": \"\", \"is_required\": \"true\", \"type\": \"word\"}, {\"suffix\": \"\", \"capitalization\": [\"title\", \"mixed\", \"upper\"], \"part_of_speech\": [\"proper noun\"], \"prefix\": \"\", \"contain_digit\": \"\", \"is_in_vocabulary\": \"\", \"is_out_of_vocabulary\": \"\", \"is_in_output\": \"true\", \"length\": [], \"shapes\": [], \"token\": [], \"is_followed_by_space\": \"\", \"is_required\": \"true\", \"type\": \"word\"}], \"identifier\": \"name_rule_05\", \"is_active\": \"true\", \"description\": \"a description\"}, {\"polarity\": [], \"pattern\": [{\"suffix\": \"\", \"capitalization\": [], \"part_of_speech\": [], \"prefix\": \"\", \"contain_digit\": \"\", \"is_in_vocabulary\": \"\", \"is_out_of_vocabulary\": \"\", \"is_in_output\": \"false\", \"length\": [], \"shapes\": [], \"token\": [\"i\"], \"is_followed_by_space\": \"\", \"is_required\": \"true\", \"type\": \"word\"}, {\"suffix\": \"\", \"capitalization\": [], \"part_of_speech\": [], \"prefix\": \"\", \"contain_digit\": \"\", \"is_in_vocabulary\": \"\", \"is_out_of_vocabulary\": \"\", \"is_in_output\": \"false\", \"length\": [], \"shapes\": [], \"token\": [\"'\"], \"is_followed_by_space\": \"\", \"is_required\": \"true\", \"type\": \"punctuation\"}, {\"suffix\": \"\", \"capitalization\": [], \"part_of_speech\": [], \"prefix\": \"\", \"contain_digit\": \"\", \"is_in_vocabulary\": \"\", \"is_out_of_vocabulary\": \"\", \"is_in_output\": \"false\", \"length\": [], \"shapes\": [], \"token\": [\"m\"], \"is_followed_by_space\": \"\", \"is_required\": \"true\", \"type\": \"word\"}, {\"suffix\": \"\", \"capitalization\": [\"title\", \"mixed\", \"upper\"], \"part_of_speech\": [\"proper noun\"], \"prefix\": \"\", \"contain_digit\": \"\", \"is_in_vocabulary\": \"\", \"is_out_of_vocabulary\": \"\", \"is_in_output\": \"true\", \"length\": [], \"shapes\": [], \"token\": [], \"is_followed_by_space\": \"\", \"is_required\": \"true\", \"type\": \"word\"}], \"identifier\": \"name_rule_06\", \"is_active\": \"true\", \"description\": \"a description\"}, {\"polarity\": [], \"pattern\": [{\"suffix\": \"\", \"capitalization\": [], \"part_of_speech\": [], \"prefix\": \"\", \"contain_digit\": \"\", \"is_in_vocabulary\": \"\", \"is_out_of_vocabulary\": \"\", \"is_in_output\": \"false\", \"length\": [], \"shapes\": [], \"token\": [\"it\"], \"is_followed_by_space\": \"\", \"is_required\": \"true\", \"type\": \"word\"}, {\"suffix\": \"\", \"capitalization\": [], \"part_of_speech\": [], \"prefix\": \"\", \"contain_digit\": \"\", \"is_in_vocabulary\": \"\", \"is_out_of_vocabulary\": \"\", \"is_in_output\": \"false\", \"length\": [], \"shapes\": [], \"token\": [\"'\"], \"is_followed_by_space\": \"\", \"is_required\": \"true\", \"type\": \"punctuation\"}, {\"suffix\": \"\", \"capitalization\": [], \"part_of_speech\": [], \"prefix\": \"\", \"contain_digit\": \"\", \"is_in_vocabulary\": \"\", \"is_out_of_vocabulary\": \"\", \"is_in_output\": \"false\", \"length\": [], \"shapes\": [], \"token\": [\"s\"], \"is_followed_by_space\": \"\", \"is_required\": \"true\", \"type\": \"word\"}, {\"suffix\": \"\", \"capitalization\": [\"title\", \"mixed\", \"upper\"], \"part_of_speech\": [\"proper noun\"], \"prefix\": \"\", \"contain_digit\": \"\", \"is_in_vocabulary\": \"\", \"is_out_of_vocabulary\": \"\", \"is_in_output\": \"true\", \"length\": [], \"shapes\": [], \"token\": [], \"is_followed_by_space\": \"\", \"is_required\": \"true\", \"type\": \"word\"}], \"identifier\": \"name_rule_07\", \"is_active\": \"true\", \"description\": \"a description\"}, {\"polarity\": [], \"pattern\": [{\"suffix\": \"\", \"capitalization\": [\"title\"], \"part_of_speech\": [], \"prefix\": \"\", \"contain_digit\": \"\", \"is_in_vocabulary\": \"\", \"is_out_of_vocabulary\": \"\", \"is_in_output\": \"true\", \"length\": [], \"shapes\": [], \"token\": [], \"is_followed_by_space\": \"\", \"is_required\": \"true\", \"type\": \"word\"}, {\"suffix\": \"\", \"capitalization\": [], \"part_of_speech\": [], \"prefix\": \"\", \"contain_digit\": \"\", \"is_in_vocabulary\": \"\", \"is_out_of_vocabulary\": \"\", \"is_in_output\": \"false\", \"length\": [], \"shapes\": [], \"token\": [\"(\", \"[\"], \"is_followed_by_space\": \"\", \"is_required\": \"true\", \"type\": \"punctuation\"}, {\"suffix\": \"\", \"capitalization\": [], \"part_of_speech\": [], \"prefix\": \"\", \"contain_digit\": \"\", \"is_in_vocabulary\": \"\", \"is_out_of_vocabulary\": \"\", \"is_in_output\": \"false\", \"length\": [], \"shapes\": [\"ddd\"], \"token\": [], \"is_followed_by_space\": \"\", \"is_required\": \"true\", \"type\": \"shape\"}], \"identifier\": \"name_rule_08\", \"is_active\": \"true\", \"description\": \"a description\"}, {\"polarity\": [], \"pattern\": [{\"suffix\": \"\", \"capitalization\": [\"title\", \"upper\", \"mixed\"], \"part_of_speech\": [], \"prefix\": \"\", \"contain_digit\": \"\", \"is_in_vocabulary\": \"\", \"is_out_of_vocabulary\": \"\", \"is_in_output\": \"true\", \"length\": [], \"shapes\": [], \"token\": [], \"is_followed_by_space\": \"\", \"is_required\": \"true\", \"type\": \"word\"}, {\"suffix\": \"\", \"capitalization\": [], \"part_of_speech\": [], \"prefix\": \"\", \"contain_digit\": \"\", \"is_in_vocabulary\": \"\", \"is_out_of_vocabulary\": \"\", \"is_in_output\": \"false\", \"length\": [], \"shapes\": [\"dddddddddd\"], \"token\": [], \"is_followed_by_space\": \"\", \"is_required\": \"true\", \"type\": \"shape\"}], \"identifier\": \"name_rule_09\", \"is_active\": \"true\", \"description\": \"a description\"}], \"results\": [{\"context\": {\"start\": 105, \"identifier\": \"name_rule_02\", \"end\": 108, \"rule_id\": 1}, \"value\": \"All\"}, {\"context\": {\"start\": 109, \"identifier\": \"name_rule_02\", \"end\": 112, \"rule_id\": 1}, \"value\": \"ALL\"}, {\"context\": {\"start\": 59, \"identifier\": \"name_rule_03\", \"end\": 62, \"rule_id\": 2}, \"value\": \"Sara\"}, {\"context\": {\"start\": 69, \"identifier\": \"name_rule_03\", \"end\": 72, \"rule_id\": 2}, \"value\": \"JILL\"}, {\"context\": {\"start\": 73, \"identifier\": \"name_rule_03\", \"end\": 76, \"rule_id\": 2}, \"value\": \"Jessie\"}, {\"context\": {\"start\": 28, \"identifier\": \"name_rule_04\", \"end\": 31, \"rule_id\": 3}, \"value\": \"JessicaLa\"}, {\"context\": {\"start\": 33, \"identifier\": \"name_rule_04\", \"end\": 36, \"rule_id\": 3}, \"value\": \"Cold\"}, {\"context\": {\"start\": 113, \"identifier\": \"name_rule_05\", \"end\": 116, \"rule_id\": 4}, \"value\": \"Ashleyb\"}, {\"context\": {\"start\": 120, \"identifier\": \"name_rule_05\", \"end\": 123, \"rule_id\": 4}, \"value\": \"Ashleya\"}, {\"context\": {\"start\": 123, \"identifier\": \"name_rule_05\", \"end\": 126, \"rule_id\": 4}, \"value\": \"AshleyC\"}, {\"context\": {\"start\": 97, \"identifier\": \"name_rule_06\", \"end\": 101, \"rule_id\": 5}, \"value\": \"Ashley\"}, {\"context\": {\"start\": 5, \"identifier\": \"name_rule_07\", \"end\": 9, \"rule_id\": 6}, \"value\": \"Jessica\"}, {\"context\": {\"start\": 77, \"identifier\": \"name_rule_08\", \"end\": 80, \"rule_id\": 7}, \"value\": \"Ashley\"}, {\"context\": {\"start\": 86, \"identifier\": \"name_rule_08\", \"end\": 89, \"rule_id\": 7}, \"value\": \"Aslll\"}, {\"context\": {\"start\": 94, \"identifier\": \"name_rule_09\", \"end\": 96, \"rule_id\": 8}, \"value\": \"Alppp\"}], \"test_tokens\": [\"Hello\", \"guy\", \"'\", \"s\", \",\", \"it\", \"'\", \"s\", \"Jessica\", \"here\", \"from\", \"the\", \"#\", \"@\", \"%\", \"%\", \"%\", \"Spa\", \".\", \"I\", \"cant\", \"say\", \"the\", \"name\", \"on\", \"here\", \",\", \"and\", \"it\", \"is\", \"JessicaLa\", \",\", \"and\", \"it\", \"is\", \"Cold\", \"\\n\", \"Hi\", \"Gentlemen\", \",\", \"My\", \"name\", \"is\", \"Ashley\", \".\", \"my\", \"name\", \"Monica\", \"I\", \"am\", \"the\", \"one\", \"and\", \",\", \"My\", \"names\", \"is\", \"Alanda\", \"\\n\", \"Name\", \":\", \"Sara\", \".\", \"I\", \"am\", \"the\", \"one\", \"and\", \",\", \"Name\", \":\", \"JILL\", \",\", \"Name\", \":\", \"Jessie\", \"\\n\", \"Ashley\", \"(\", \"702\", \")\", \"628\", \"-\", \"9035\", \"XOXO\", \".\", \"Aslll\", \"(\", \"702\", \")\", \"628\", \"-\", \"9035\", \"XOXO\", \"Alppp\", \"7026289035\", \"\\n\", \"I\", \"'\", \"m\", \"Ashley\", \"I\", \"'\", \"m\", \"bored\", \"i\", \"am\", \"All\", \",\", \"I\", \"am\", \"ALL\", \"\\n\", \"this\", \"is\", \"Ashleyb\", \"I\", \"'\", \"m\", \"bored\", \"This\", \"is\", \"Ashleya\", \"This\", \"is\", \"AshleyC\"], \"test_text\": \"Hello guy's, it's Jessica here from the #@%%% Spa. I cant say the name on here, and it is JessicaLa, and it is Cold\\nHi Gentlemen, My name is Ashley . my name Monica I am the one and, My names is Alanda\\nName : Sara . I am the one and, Name: JILL , Name:Jessie\\nAshley (702)628-9035 XOXO . Aslll (702) 628-9035 XOXO Alppp 7026289035\\nI'm Ashley I'm bored i am All, I am ALL\\nthis is Ashleyb I'm bored This is Ashleya  This is AshleyC\"}\n",
      "[\n",
      "  {\n",
      "    \"context\": {\n",
      "      \"start\": 105, \n",
      "      \"identifier\": \"name_rule_02\", \n",
      "      \"end\": 108, \n",
      "      \"rule_id\": 1\n",
      "    }, \n",
      "    \"value\": \"All\"\n",
      "  }, \n",
      "  {\n",
      "    \"context\": {\n",
      "      \"start\": 109, \n",
      "      \"identifier\": \"name_rule_02\", \n",
      "      \"end\": 112, \n",
      "      \"rule_id\": 1\n",
      "    }, \n",
      "    \"value\": \"ALL\"\n",
      "  }, \n",
      "  {\n",
      "    \"context\": {\n",
      "      \"start\": 59, \n",
      "      \"identifier\": \"name_rule_03\", \n",
      "      \"end\": 62, \n",
      "      \"rule_id\": 2\n",
      "    }, \n",
      "    \"value\": \"Sara\"\n",
      "  }, \n",
      "  {\n",
      "    \"context\": {\n",
      "      \"start\": 69, \n",
      "      \"identifier\": \"name_rule_03\", \n",
      "      \"end\": 72, \n",
      "      \"rule_id\": 2\n",
      "    }, \n",
      "    \"value\": \"JILL\"\n",
      "  }, \n",
      "  {\n",
      "    \"context\": {\n",
      "      \"start\": 73, \n",
      "      \"identifier\": \"name_rule_03\", \n",
      "      \"end\": 76, \n",
      "      \"rule_id\": 2\n",
      "    }, \n",
      "    \"value\": \"Jessie\"\n",
      "  }, \n",
      "  {\n",
      "    \"context\": {\n",
      "      \"start\": 28, \n",
      "      \"identifier\": \"name_rule_04\", \n",
      "      \"end\": 31, \n",
      "      \"rule_id\": 3\n",
      "    }, \n",
      "    \"value\": \"JessicaLa\"\n",
      "  }, \n",
      "  {\n",
      "    \"context\": {\n",
      "      \"start\": 33, \n",
      "      \"identifier\": \"name_rule_04\", \n",
      "      \"end\": 36, \n",
      "      \"rule_id\": 3\n",
      "    }, \n",
      "    \"value\": \"Cold\"\n",
      "  }, \n",
      "  {\n",
      "    \"context\": {\n",
      "      \"start\": 113, \n",
      "      \"identifier\": \"name_rule_05\", \n",
      "      \"end\": 116, \n",
      "      \"rule_id\": 4\n",
      "    }, \n",
      "    \"value\": \"Ashleyb\"\n",
      "  }, \n",
      "  {\n",
      "    \"context\": {\n",
      "      \"start\": 120, \n",
      "      \"identifier\": \"name_rule_05\", \n",
      "      \"end\": 123, \n",
      "      \"rule_id\": 4\n",
      "    }, \n",
      "    \"value\": \"Ashleya\"\n",
      "  }, \n",
      "  {\n",
      "    \"context\": {\n",
      "      \"start\": 123, \n",
      "      \"identifier\": \"name_rule_05\", \n",
      "      \"end\": 126, \n",
      "      \"rule_id\": 4\n",
      "    }, \n",
      "    \"value\": \"AshleyC\"\n",
      "  }, \n",
      "  {\n",
      "    \"context\": {\n",
      "      \"start\": 97, \n",
      "      \"identifier\": \"name_rule_06\", \n",
      "      \"end\": 101, \n",
      "      \"rule_id\": 5\n",
      "    }, \n",
      "    \"value\": \"Ashley\"\n",
      "  }, \n",
      "  {\n",
      "    \"context\": {\n",
      "      \"start\": 5, \n",
      "      \"identifier\": \"name_rule_07\", \n",
      "      \"end\": 9, \n",
      "      \"rule_id\": 6\n",
      "    }, \n",
      "    \"value\": \"Jessica\"\n",
      "  }, \n",
      "  {\n",
      "    \"context\": {\n",
      "      \"start\": 77, \n",
      "      \"identifier\": \"name_rule_08\", \n",
      "      \"end\": 80, \n",
      "      \"rule_id\": 7\n",
      "    }, \n",
      "    \"value\": \"Ashley\"\n",
      "  }, \n",
      "  {\n",
      "    \"context\": {\n",
      "      \"start\": 86, \n",
      "      \"identifier\": \"name_rule_08\", \n",
      "      \"end\": 89, \n",
      "      \"rule_id\": 7\n",
      "    }, \n",
      "    \"value\": \"Aslll\"\n",
      "  }, \n",
      "  {\n",
      "    \"context\": {\n",
      "      \"start\": 94, \n",
      "      \"identifier\": \"name_rule_09\", \n",
      "      \"end\": 96, \n",
      "      \"rule_id\": 8\n",
      "    }, \n",
      "    \"value\": \"Alppp\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "field_rules = {\n",
    "  \"rules\": [\n",
    "    rule_01, \n",
    "    rule_02,\n",
    "    rule_03,\n",
    "    rule_04,\n",
    "    rule_05,\n",
    "    rule_06,\n",
    "    rule_07,\n",
    "    rule_08,\n",
    "    rule_09\n",
    "  ],\n",
    "    \"test_text\": d['text'],\n",
    "    \"test_tokens\": c.extract_tokens_from_crf(c.extract_crftokens(d['text'], lowercase=False))\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "results = c.extract_using_custom_spacy(d, config, field_rules=field_rules)\n",
    "print results\n",
    "\n",
    "field_rules['results']=results\n",
    "\n",
    "s = json.dumps(field_rules)\n",
    "\n",
    "print s\n",
    "import codecs\n",
    "o = codecs.open('path_to_file', 'w')\n",
    "o.write(s)\n",
    "o.close()\n",
    "\n",
    "print json.dumps(results, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'suffix': '', 'capitalization': [], 'part_of_speech': [], 'prefix': '', 'contain_digit': '', 'is_in_vocabulary': '', 'is_out_of_vocabulary': '', 'is_in_output': 'false', 'length': [], 'shapes': [], 'token': ['hello'], 'is_followed_by_space': '', 'is_required': 'true', 'type': 'word'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print word_token(token=[\"hello\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:etk_env]",
   "language": "python",
   "name": "conda-env-etk_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
