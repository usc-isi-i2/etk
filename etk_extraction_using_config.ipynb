{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Run content extraction on html document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Readability and Title Extraction\n",
    "In the following example, we will run the `readability` extractor and the `title` extractor on the html document.  \n",
    "The extraction is controlled by an `extraction_config` and the input is json document with `html` document embedded in it.  \n",
    "\n",
    "Let's breakdown the extraction_config:  \n",
    "> `input_path`  \n",
    "\n",
    "specifies the path where the html content is in the json  \n",
    "> `extractors.readability`  \n",
    "\n",
    "sets up `etk` to run readability extractor on the `input_path`\n",
    "\n",
    "> `strict: yes`\n",
    "\n",
    "makes `readability` extractor more precise. ```strict: no``` will result in more content getting extracted from the html as main content  \n",
    "> `extractors.title`  \n",
    "\n",
    "sets up etk to run the `title` extractor\n",
    "\n",
    "#### Output  \n",
    "The output will be under the field `content_extraction` in the input json document.   \n",
    "It should have `content_relaxed` corresponding to ```strict: no``` and `content_strict` for ```strict: yes```  \n",
    "It should also contain `title`\n",
    "\n",
    "```\n",
    "{\n",
    "    content_extraction: {\n",
    "        content_strict: {\n",
    "            text: \"...\"\n",
    "        },\n",
    "        content_relaxed: {\n",
    "            text: \"...\"\n",
    "        },\n",
    "        title: {\n",
    "            text: \"...\"\n",
    "        }\n",
    "}\n",
    "```\n",
    "\n",
    "**All the content extraction values are assigned to a field called `text` under the corresponding content_extraction**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"content_relaxed\": {\n",
      "    \"text\": \"\\n \\n \\n \\n \\n \\n \\n smoothlegs24  28 \\n \\n \\n chrissy391  27 \\n \\n \\n My name is Helena height 160cms weight 55 kilos  contact me at escort.here@gmail.com           jefferson ave         age: 23 HrumpMeNow  28 \\n \\n \\n xxtradition  24 \\n \\n \\n jumblyjumb  26 \\n \\n \\n claudia77  26 \\n \\n \\n gushinPuss  28 \\n \\n \\n Littlexdit  25 \\n \\n \\n PinkSweets2  28 \\n \\n \\n withoutlimit  27 \\n \\n \\n bothOfUs3  28 \\n \\n \\n lovelylips  27 \\n \\n \\n killerbod  27 \\n \\n \\n Littlexdit  27 \\n \\n \\n azneyes  23 \\n \\n \\n \\n \\n \\n Escort's Phone: \\n \\n \\n323-452-2013  \\n \\n Escort's Location: \\nLos Angeles, California  \\n Escort's Age:   23   Date of Escort Post:   Jan 02nd 6:46am \\n REVIEWS:   \\n READ AND CREATE REVIEWS FOR THIS ESCORT   \\n \\n \\n \\n \\n \\nThere are  50  girls looking in  .\\n VIEW GIRLS \\n \\nHey I'm luna 3234522013 Let's explore , embrace and indulge in your favorite fantasy  % independent. discreet no drama Firm Thighs and Sexy. My Soft skin & Tight Grip is exactly what you deserve Call or text   Fetish friendly   Fantasy friendly   Party friendly 140 Hr SPECIALS 3234522013.\\u00a0Call  323-452-2013 .  Me and my friends are on EZsex  soooo you can find us all on there if you want... skittlegirl \\n \\u00a0\\u00a0\\n \\n \\u00a0\\u00a0\\n \\n \\u00a0\\u00a0\\n Call me on my cell at 323-452-2013. Date of ad: 2017-01-02 06:46:00 \\n \\n \\n \\n\"\n",
      "  }, \n",
      "  \"content_strict\": {\n",
      "    \"text\": \"\\n \\n \\n \\n \\n \\n smoothlegs24  28 \\n \\n \\n chrissy391  27 \\n \\n \\n My name is Helena height 160cms weight 55 kilos  contact me at escort.here@gmail.com           jefferson ave         age: 23 HrumpMeNow  28 \\n \\n \\n xxtradition  24 \\n \\n \\n jumblyjumb  26 \\n \\n \\n claudia77  26 \\n \\n \\n gushinPuss  28 \\n \\n \\n Littlexdit  25 \\n \\n \\n PinkSweets2  28 \\n \\n \\n withoutlimit  27 \\n \\n \\n bothOfUs3  28 \\n \\n \\n lovelylips  27 \\n \\n \\n killerbod  27 \\n \\n \\n Littlexdit  27 \\n \\n \\n azneyes  23 \\n \\n \\n \\n \\n \\n Escort's Phone: \\n \\n \\n323-452-2013  \\n \\n Escort's Location: \\nLos Angeles, California  \\n Escort's Age:   23   Date of Escort Post:   Jan 02nd 6:46am \\n REVIEWS:   \\n READ AND CREATE REVIEWS FOR THIS ESCORT   \\n \\n \\n \\n \\n \\nThere are  50  girls looking in  .\\n VIEW GIRLS \\n \\nHey I'm luna 3234522013 Let's explore , embrace and indulge in your favorite fantasy  % independent. discreet no drama Firm Thighs and Sexy. My Soft skin & Tight Grip is exactly what you deserve Call or text   Fetish friendly   Fantasy friendly   Party friendly 140 Hr SPECIALS 3234522013.\\u00a0Call  323-452-2013 .  Me and my friends are on EZsex  soooo you can find us all on there if you want... skittlegirl \\n \\u00a0\\u00a0\\n \\n \\u00a0\\u00a0\\n \\n \\u00a0\\u00a0\\n Call me on my cell at 323-452-2013. Date of ad: 2017-01-02 06:46:00 \\n \\n \\n\"\n",
      "  }, \n",
      "  \"title\": {\n",
      "    \"text\": \"323-452-2013 ESCORT ALERT! - Luna The Hot Playmate (323) 452-2013 - 23\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from etk.core import Core\n",
    "import  json\n",
    "import pprint\n",
    "import codecs\n",
    "\n",
    "extraction_config = {'content_extraction': {\n",
    "            \"input_path\": \"raw_content\",\n",
    "            \"extractors\": {\n",
    "              \"readability\": [\n",
    "                {\n",
    "                  \"strict\": \"yes\",\n",
    "                  \"extraction_policy\": \"keep_existing\"\n",
    "                },\n",
    "                {\n",
    "                  \"strict\": \"no\",\n",
    "                  \"extraction_policy\": \"keep_existing\",\n",
    "                  \"field_name\": \"content_relaxed\"\n",
    "                }\n",
    "              ],\n",
    "              \"title\": {\n",
    "                 \"extraction_policy\": \"keep_existing\"\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "# read the json document from disk\n",
    "doc = json.load(codecs.open('etk/unit_tests/ground_truth/1.jl', 'r'))\n",
    "c = Core(extraction_config=extraction_config)\n",
    "r = c.process(doc)\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "print json.dumps(r['content_extraction'], indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "  \n",
    "#### Landmark Extractor\n",
    "Now, lets run `landmark-extractor` on the html document. You can read about Inferlink's landmark-extractor [here](https://github.com/inferlink/landmark-extractor)  \n",
    "**tl;dr** landmark-extractor applies a number of pre-trained rules to the html document. These rules are regex based and can be created in the landmark-extractor tool.\n",
    "\n",
    "`extraction_config` for landmark-extractor:  \n",
    "\n",
    "> `extractors.landmark`  \n",
    "\n",
    "sets up `etk` to run landmark-extractor on the `input_path`\n",
    "\n",
    "> `extractors.landmark.landmark_threshold`  \n",
    "\n",
    "the ratio of number of successful landmark rules to the total number of landmark rules for that domain should be greater than or equal to this number. Otherwise `etk` will ignore this landmark extraction\n",
    "\n",
    "> `resources.landmark`\n",
    "\n",
    "the place in the `extraction_config` to specify the landmark rules files.\n",
    "\n",
    "\n",
    "#### Output  \n",
    "The output will be under the field `content_extraction` in the input json document.   \n",
    "\n",
    "It should contain the field `inferlink_extractions`\n",
    "\n",
    "```\n",
    "{\n",
    "    content_extraction: {\n",
    "        inferlink_extractions: {\n",
    "            inferlink_age:{\n",
    "                text: \"...\"\n",
    "            },\n",
    "            inferlink_posting-date:{\n",
    "                text: \"...\"\n",
    "            },\n",
    "            ...\n",
    "        }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"inferlink_extractions\": {\n",
      "    \"inferlink_location\": {\n",
      "      \"text\": \"Los Angeles, California\"\n",
      "    }, \n",
      "    \"inferlink_age\": {\n",
      "      \"text\": \"23\"\n",
      "    }, \n",
      "    \"inferlink_phone\": {\n",
      "      \"text\": \"323-452-2013\"\n",
      "    }, \n",
      "    \"inferlink_posting-date\": {\n",
      "      \"text\": \"2017-01-02 06:46\"\n",
      "    }, \n",
      "    \"inferlink_description\": {\n",
      "      \"text\": \"Hey I'm luna 3234522013 Let's explore , embrace and indulge in your favorite fantasy % independent. discreet no drama Firm Thighs and Sexy. My Soft skin & Tight Grip is exactly what you deserve Call or text Fetish friendly Fantasy friendly Party friendly 140 Hr SPECIALS 3234522013\"\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from etk.core import Core\n",
    "import pprint\n",
    "import json, codecs\n",
    "\n",
    "rules_file_path = 'etk/unit_tests/resources/consolidated_rules.json'\n",
    "e_config = {\n",
    "    \"resources\": {\n",
    "        \"landmark\": [\n",
    "            rules_file_path\n",
    "        ]\n",
    "        }, \n",
    "    'content_extraction': {\n",
    "        \"input_path\": \"raw_content\",\n",
    "        \"extractors\": {\n",
    "            \"landmark\": {\n",
    "                \"extraction_policy\": \"keep_existing\",\n",
    "                \"landmark_threshold\": 0.5\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "doc = json.load(codecs.open('etk/unit_tests/ground_truth/1.jl', 'r'))\n",
    "c = Core(extraction_config=e_config)\n",
    "r = c.process(doc)\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "print json.dumps(r['content_extraction'], indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "# Run data extraction on text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's extract some data types from the text. Data extraction is controlled by the `data_extraction` part of the `extraction_config`.  \n",
    "\n",
    "The following example demonstrates two basic data extraction techniques, `extract_using_dictionary` and `extract_using_regex`\n",
    "\n",
    "#### `input_path`  \n",
    "Usually the data extraction runs after the [content extraction](# Run content extraction on html document), this ensures presence of the field `text` with the actual value.  \n",
    "\n",
    "The `input_path` is defined like this ``*.*.text.`parent` ``. This will match all the objects in the input json which are at the  third level of nesting. \n",
    "For example, if the input json looks like this ,\n",
    "\n",
    "```\n",
    "{\n",
    "    content_extraction: {\n",
    "        content_strict: {\n",
    "            text: \"...\"\n",
    "        },\n",
    "        content_relaxed: {\n",
    "            text: \"...\"\n",
    "        },\n",
    "        title: {\n",
    "            text: \"...\"\n",
    "        }\n",
    "}\n",
    "```  \n",
    "to match all the `text` fields in this case, the `input_path` should say ``*.*.text.`parent` ``\n",
    "\n",
    "The `` `parent` `` part of the  `input_path` provides the object at the one level up from the matching `text` field. Data extraction will tokenize the text and place them in the same object. This will be clear from the example below.\n",
    "\n",
    "**If you do not want to run content extraction prior to data extraction, ensure that the field is called `text`. Support for any field name incoming**\n",
    "\n",
    "#### `extract_using_dictionary`  \n",
    "Given a list of things(in this example, female names), this method will extract all occurences of names in the list from the text.  \n",
    "\n",
    "Let's breakdown the `extraction_config` for `extract_using_dictionary`:  \n",
    "\n",
    "> `config.dictionary` (required)\n",
    "\n",
    "specifies the name of the input dictionary of things to extract. This name should be present in the `resources.dictionaries` part of the `extraction_config`.\n",
    "\n",
    "\n",
    "#### `extact_using_regex`  \n",
    "Given a regular expression, this method will match it against the text.  \n",
    "The `extraction_config` for `extract_using_regex`:\n",
    "\n",
    "> `config.regex`  (required)\n",
    "\n",
    "the regular expression to be matched\n",
    "\n",
    "> `config.regex_options` (optional)\n",
    "\n",
    "Optional regular expression [flags](https://docs.python.org/2/library/re.html#regular-expression-syntax)\n",
    "\n",
    "#### Generic config options\n",
    "\n",
    "> `config.ngrams`  (optional)\n",
    "\n",
    "specifies the ngrams into which text will be tokenized to match the names in the dictionary.\n",
    "\n",
    "> `config.joiner` (optional)\n",
    "\n",
    "join the tokens back using this delimiter\n",
    "\n",
    "> `config.pre_process` (optional)\n",
    "\n",
    "apply this lambda function to the text before extraction\n",
    "\n",
    "> `config.pre_filter` (optional)\n",
    "\n",
    "apply this filter to the text before extraction\n",
    "\n",
    "> `config.post_filter` (optional)\n",
    "\n",
    "apply this filter to the extracted values\n",
    "\n",
    "**the functions in `pre_process`, `pre_filter` and `post_filter` can be either lambdas or [extraction methods](link somewhere)**  \n",
    "\n",
    "#### Output  \n",
    "Let's say that the object matching the `input_path` looks like this,\n",
    "\n",
    "```\n",
    "{\n",
    "    text: \"...\"\n",
    "}\n",
    "```\n",
    "And we ran data extraction with `extraction_config` as the one in the example below, the output should look like this,\n",
    "\n",
    "```\n",
    "{\n",
    "    text: \"...\",\n",
    "    tokens: ['...', '.'] ,\n",
    "    simple_tokens: ['...', '.'],\n",
    "    data_extraction: {\n",
    "        name: {\n",
    "            extract_using_dictionary: {\n",
    "                results: [\n",
    "                    {\n",
    "                        context: '...',\n",
    "                        origin: '...',\n",
    "                        value: '...'\n",
    "                    },\n",
    "                    ...\n",
    "                ]\n",
    "            },\n",
    "            extract_using_regex: {\n",
    "            results: [\n",
    "                {\n",
    "                   context: '...',\n",
    "                        origin: '...',\n",
    "                        value: '...'\n",
    "                    },\n",
    "                    ... \n",
    "                }\n",
    "            ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "The `tokens` are the annotated tokens and `simple_tokens` are the more traditional list of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": {\n",
      "    \"extract_using_dictionary\": {\n",
      "      \"results\": [\n",
      "        {\n",
      "          \"origin\": {\n",
      "            \"score\": 1.0, \n",
      "            \"segment\": \"readability_strict\", \n",
      "            \"method\": \"other_method\"\n",
      "          }, \n",
      "          \"context\": {\n",
      "            \"start\": 10, \n",
      "            \"end\": 11, \n",
      "            \"text\": \"my name is helena height 160cms weight\"\n",
      "          }, \n",
      "          \"value\": \"helena\"\n",
      "        }, \n",
      "        {\n",
      "          \"origin\": {\n",
      "            \"score\": 1.0, \n",
      "            \"segment\": \"readability_strict\", \n",
      "            \"method\": \"other_method\"\n",
      "          }, \n",
      "          \"context\": {\n",
      "            \"start\": 136, \n",
      "            \"end\": 137, \n",
      "            \"text\": \"i ' m luna 3234522013 let '\"\n",
      "          }, \n",
      "          \"value\": \"luna\"\n",
      "        }\n",
      "      ]\n",
      "    }, \n",
      "    \"extract_using_regex\": {\n",
      "      \"results\": [\n",
      "        {\n",
      "          \"origin\": {\n",
      "            \"score\": 1.0, \n",
      "            \"segment\": \"readability_strict\", \n",
      "            \"method\": \"other_method\"\n",
      "          }, \n",
      "          \"context\": {\n",
      "            \"start\": 56, \n",
      "            \"end\": 73, \n",
      "            \"text\": \" 27 \\n \\n \\n My name is Helena height 16\"\n",
      "          }, \n",
      "          \"value\": \"Helena\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from etk.core import Core\n",
    "import pprint\n",
    "import json, codecs\n",
    "\n",
    "extraction_config = {\n",
    "  \"resources\": {\n",
    "    \"dictionaries\": {\n",
    "      \"women_name\": \"etk/unit_tests/resources/female-names.json.gz\"\n",
    "    }\n",
    "  },\n",
    "  \"data_extraction\": [\n",
    "    {\n",
    "      \"input_path\": \"*.content_strict.text.`parent`\",\n",
    "      \"fields\": {\n",
    "        \"name\": {\n",
    "          \"extractors\": {\n",
    "            \"extract_using_dictionary\": {\n",
    "              \"config\": {\n",
    "                \"dictionary\": \"women_name\",\n",
    "                \"ngrams\": 1,\n",
    "                \"joiner\": \" \",\n",
    "                \"pre_process\": [\n",
    "                  \"x.lower()\"\n",
    "                ],\n",
    "                \"pre_filter\": [\n",
    "                  \"x\"\n",
    "                ],\n",
    "                \"post_filter\": [\n",
    "                  \"isinstance(x, basestring)\"\n",
    "                ]\n",
    "              },\n",
    "              \"extraction_policy\": \"keep_existing\"\n",
    "            },\n",
    "            \"extract_using_regex\": {\n",
    "              \"config\": {\n",
    "                \"include_context\": \"true\",\n",
    "                \"regex\": \"(?:my[\\\\s]+name[\\\\s]+is[\\\\s]+([-a-z0-9@$!]+))\",\n",
    "                \"regex_options\": [\n",
    "                  \"IGNORECASE\"\n",
    "                ],\n",
    "                \"pre_filter\": [\n",
    "                  \"x.replace('\\\\n', '')\",\n",
    "                  \"x.replace('\\\\r', '')\"\n",
    "                ]\n",
    "              },\n",
    "              \"extraction_policy\": \"replace\"\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "# read the json document from disk\n",
    "doc = json.load(codecs.open('etk/unit_tests/ground_truth/1_content_extracted.jl', 'r'))\n",
    "c = Core(extraction_config=extraction_config)\n",
    "r = c.process(doc)\n",
    "print json.dumps(r['content_extraction']['content_strict']['data_extraction'], indent=2)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:etk_env]",
   "language": "python",
   "name": "conda-env-etk_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
